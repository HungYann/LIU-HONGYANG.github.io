---
layout: post
author: LIU,HONGYANG
tags: [Machine Learning]
---







一：原理描述**

　　今天学习第一个机器学习算法，k-近邻算法。

　　基本原理：1使用存在的样本数据集，并且每个样本数据集中都存在标签。2.知道样本数据集和标签对应的关系。3.输入一个没有标签的数据后，将新输入的每个样本特征与已经存在的样本特征一一比较，接着通过算法提取样本中最相似的样本。4.选择样本数据k个最相似的值，k一般不操过20。5最后从k个相似数据中选取出现次数最多的数据作为预测值。

　　k-算法中预测值的结果很大依赖k值的选取，使用的数据范围是数值型和标称型。在KNN算法中，是通过计算对象之间的距离来作为对象之间非相似指标，这个距离一般是欧式距离或曼哈顿距离：

　　![img](http://images2017.cnblogs.com/blog/1067977/201709/1067977-20170912162319844-1573541831.png)

　　k领近算法的描述为：

　　1.计算测试数据与各个训练数据之间的距离；

　　2.按照距离递增关系进行排序；

　　3.选取距离最小的k个值；

　　4.确定前k个点中所在类别的出现频率；

　　5.返回k个点中出现类别最高的样本值作为预测数据；

**二.实现方法**

 

```
#coding:utf-8

from numpy import *
import operator

##给出训练数据以及对应的类别
def createDataSet():
    group = array([[1.0,2.0],[1.2,0.1],[0.1,1.4],[0.3,3.5]])
    labels = ['A','A','B','B']
    return group,labels

###通过KNN进行分类
def classify(input,dataSet,label,k):
    dataSize = dataSet.shape[0]
    ####计算欧式距离
    diff = tile(input,(dataSize,1)) - dataSet
    sqdiff = diff ** 2
    squareDist = sum(sqdiff,axis = 1)###行向量分别相加，从而得到新的一个行向量
    dist = squareDist ** 0.5
    
    ##对距离进行排序
    sortedDistIndex = argsort(dist)##argsort()根据元素的值从大到小对元素进行排序，返回下标

    classCount={}
    for i in range(k):
        voteLabel = label[sortedDistIndex[i]]
        ###对选取的K个样本所属的类别个数进行统计
        classCount[voteLabel] = classCount.get(voteLabel,0) + 1
    ###选取出现的类别次数最多的类别
    maxCount = 0
    for key,value in classCount.items():
        if value > maxCount:
            maxCount = value
            classes = key

    return classes
```





运行：

```
import KNN
from numpy import *
dataSet,labels = KNN.createDataSet()
input = array([1.1,0.3])
K = 3
output = KNN.classify(input,dataSet,labels,K)
print("测试数据为:",input,"分类结果为：",output)
```

 