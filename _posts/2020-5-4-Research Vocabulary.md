---
layout: post
author: LIU,HONGYANG
tags: [Research]
---



##### A

> adopted 

```
such hashtags are conventions created by users that become largely adopted
```





##### B

> boots

```
boosts/improve the classfication performance
```





##### C



> Categorize

```
our goal is to categorize a tweet into one of the three sentiment categoris: positive,negative, neutral
```



##### 







> Compose



```
We exploited the syntax of the tweets to compose our features
```



##### D





##### E



> exploit

```
We exploited the syntax of the tweets to compose our features
```





##### F



##### G



##### H

> highlight



```
highlight teh most important attributes for spam detection onTwitter
```





##### I

> Implement

```
we implement a 2-stem sentiment detection framework
```



##### J



##### K



##### L



##### M



> motivated

```
we are motivated to develop an abstract representation of tweets.
```







##### N



##### O



##### P



##### Q



##### R

> reflect



```
reflect shocking and breaking news or events that appear in the mass media.
```



##### S



> strategy

```
this strategy might not be effective, as shown in our experiments.
```



> subjectivity

```
predict the subjectivity of a given tweet
```



> retrieved

```
tweets can also be retrieved through search systems or other tools
```



> obfuscated

```
are obfuscated by URL shorteners
```





##### T



##### U

##### V



##### W













##### P



> propose

```
We propose the use of two sets of features.
```



> Perform



```
we perform a cleaning process over this data to assure some reasonable quality
```





##### 层次顺序

```
the first step targets on distinguishing subjective tweets from non-subject tweets, the second one further classifies the subjective tweets into positive and negative
```



```
in this paper, we firstly address the issue of detecting spammers on Twitter. To do it, we propose a 4-step approach. First, we crawled a near-complete dataset from Twitter. To do it,we propose a 4-step approach. First, we crawled a near-complete dataset from Twitter, comtaining more than 54 million users, 1.9 billion links, and almost 1.8 billion tweets.

Second, we created a labeled collection with users "manully" classified as spammers and non-spammers. Third we conducted a study about the characteristics of tweet content and users behavviour on Twitter aiming at understanding their relative discriminative power to distinguish spammers and non-spammers. Lastly, we investigate the feasibility of applying a superivised machine learning method to identify spammmers.
```





##### 连词

```
However

Although
```





