---
layout: post
author: LIU,HONGYANG
tags: [Go]
---

## 单点启动

- 1.如果集群是第一次启动，需要格式化NameNode:
```shell
hadoop namenode -format
```

- 2.在某一台机器上启动NameNode节点：
```shell
hadoop-daemon.sh start namenode
```

- 3.在某一台机器上启动DataNode节点：
```shell
hadoop-daemon.sh start datanode
```

## 群起启动
1. 先配置各机器的ssh

2. 配置slaves文件
```shell
$HADOOP_HOME=/etc/hadoop/slaves
```

- 在文件中增加以下内容：
```shell
hadoop101
hadoop102
hadoop103
```

- 3.如果第一次启动集群，需要格式化NameNode，这里使用的是hdfs，不是单点启动时的hadoop
```shell
hdfs namenode -format
```

- 4.启动hdfs
```shell
start-dfs.sh
```

- 5.启动yarn
```shell
start-yarn.sh
```

## 查看是否启动成功

http://主机名或IP地址:50090/status.html

## 集群启动/停止方式总结

1. 各个服务组件逐一启动/停止
- 分别启动/停止HDFS组件
```shell
hadoop-daemon.sh start / stop namenode / datanode / secondarynamenode
```
- 启动/停止Yarn
```shell
yarn-daemon.sh start / stop resourcemanager / nodemanager
```

2. 各个模块分开启动/停止（前提配置ssh）

- 整体启动/停止HDFS
```shell
start-dfs.sh / stop-dfs.sh
```

- 整体启动/停止Yarn
```shell
start-yarn.sh / stop-yarn.sh
```

- HDFS、Yarn同时启动、停止
```shell
start-all.sh  /  stop-all.sh
```

## 参考

https://www.cnblogs.com/sunbr/p/13270072.html#%E5%8D%95%E7%82%B9%E5%90%AF%E5%8A%A8
