---
layout: post
author: LIU,HONGYANG
tags: [Spark]
---







##### 1.下载

下载Apache Spark



![Screenshot 2020-05-28 at 12.35.15](https://tva1.sinaimg.cn/large/007S8ZIlgy1gf8288yyohj31160cwgo8.jpg)





##### 2.spakr安装

**spark目录**



bin: 可执行文件

core，streaming，python：主要包含源代码

examples:实例





**运行./pyspark**



![image-20200528124952000](https://tva1.sinaimg.cn/large/007S8ZIlgy1gf82jbbvgtj30vk06sq40.jpg)





**修改日志**



修改log4j.properties.template为log4j.properties





##### 3.spark开发环境





1.下载scala插件



2.重启idea



3.新建Scala项目，选择SBT包



scala开发环境中要注意开发版本匹配的问题



![image-20200528131416277](https://tva1.sinaimg.cn/large/007S8ZIlgy1gf838r4za6j313n0u0n79.jpg)





4.开发第一个Spark程序



> 配置ssh无密码登录：

```
ssh-keygen

进入.ssh目录

cat id_rsa.pub>authorized_keys

chmod 600 authorised_keys

ssh localhost
```





