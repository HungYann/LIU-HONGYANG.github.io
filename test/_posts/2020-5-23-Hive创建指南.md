---
layout: post
author: LIU,HONGYYANG
tags: [Hadoop]
---



### 修改系统命令

```
gedit ~/.bashrc
```





### DDL



##### Data Defination Language(DDL Operations)



```shell
CREATE TABLE pokes(foo INT,bar STRING);
CREATE TABLE invites (foo INT, bar STRING) PARTITIONED BY (ds STRING);
```



##### Browsing through Tables



```shell
show tables;
```



lists all the tables:

```shell
show tables ".*s";
```



```shell
Describe invites;
```



##### Altering and dropping table

```
ALTER TABLE events RENAME TO 3koobecaf;
ALTER TABLE pokes ADD COLUMNS (new_col INT);
```



##### Dropping tables

```
DROP TABLE pokes;
```





### 数据库



>  创建数据库







![Screenshot 2020-05-26 at 00.14.28](https://tva1.sinaimg.cn/large/007S8ZIlgy1gf5pox1o9xj30k0022dfy.jpg)





![Screenshot 2020-05-26 at 00.16.42](https://tva1.sinaimg.cn/large/007S8ZIlgy1gf5ppmc7gzj30k60403yv.jpg)





> 创建表单





采用分隔符","

create table cars(Car string,MPG double,Cylinders int,Displacement double,Horsepower double, Weight double,Acceleration double,Model int,Origin string) row format delimited fields terminated by ',';





采用分隔符";"

FAILED: ParseException line 1:196 mismatched input '<EOF>' expecting StringLiteral near 'by' in table row format's field separator

```sql
create table mycar2(Car string,MPG double,Cylinders int,Displacement double,Horsepower double, Weight double,Acceleration double,Model int,Origin string)row format delimited fields terminated by '\073';
```



![Screenshot 2020-05-26 at 00.21.56](https://tva1.sinaimg.cn/large/007S8ZIlgy1gf5ppx71qxj30kc030aaj.jpg)





![Screenshot 2020-05-26 at 00.51.17](https://tva1.sinaimg.cn/large/007S8ZIlgy1gf5pra3qv5j30z002i0t8.jpg)





![Screenshot 2020-05-26 at 00.22.14](https://tva1.sinaimg.cn/large/007S8ZIlgy1gf5pq4axotj30k002274e.jpg)







> 导入数据



```sql
 load data local inpath '/home/student/Desktop/cars.csv' overwrite into table mycar2;
```



![Screenshot 2020-05-26 at 00.27.16](https://tva1.sinaimg.cn/large/007S8ZIlgy1gf5pqx0nsxj30ka02ujrs.jpg)





> 选择数据范围



![Screenshot 2020-05-26 at 11.44.52](https://tva1.sinaimg.cn/large/007S8ZIlgy1gf5prsiigzj30ke076q40.jpg)





### 实验教程：



![image-20200526121040062](https://tva1.sinaimg.cn/large/007S8ZIlgy1gf5q5xxrocj31da0ge0v6.jpg)



```
hdfs dfs -put ~/Desktop/lab_leo.txt /user/hdfs/lab_test/
```



```
hdfs dfs -cat /user/hdfs/lab_test/leo.txt
```





![image-20200526122944917](https://tva1.sinaimg.cn/large/007S8ZIlgy1gf5qprhrmej30x20g2wi2.jpg)



1.

```
insert into leo_car values('Chevrolet Chevelle Malibu',18,8,307,130,3504,12,70,'US'),('Buick Skylark 320',15,8,350,165,3693,11.5,70,'US'),('Plymouth Satellite',18,8,318,150,3436,11,70,'US'),('AMC Rebel SST',16,8,304,150,3433,12,70,'US'),('Ford Torino',17,8,302,140,3449,10.5,70,'UK');
```





2.



FAILED: SemanticException [Error 10294]: Attempt to do update or delete using transaction manager that does not support these operations.



**说明：初始时这三个表没有数据，如果不添加数据，会报以下错误： org.apache.hadoop.hive.ql.lockmgr.DbTxnManager FAILED: Error in acquiring locks: Error communicating with the metastore**

![image-20200526125555760](https://tva1.sinaimg.cn/large/007S8ZIlgy1gf5ri75fawj30sm01mglu.jpg)



```
update leo_car set horsepower=1 where horsepower=120;
```



3.

```
delete from leo_car where origin="US"
```



4.

```
select * from leo_car where displacement<320 and origin="US"
```



##### Hive支持事务：



1.修改hive-site.xml



```xml
property>
    <name>hive.support.concurrency</name>
    <value>true</value>
</property>
<property>
    <name>hive.exec.dynamic.partition.mode</name>
    <value>nonstrict</value>
</property>
<property>
    <name>hive.txn.manager</name>
    <value>org.apache.hadoop.hive.ql.lockmgr.DbTxnManager</value>
</property>
<property>
    <name>hive.compactor.initiator.on</name>
    <value>true</value>
</property>
<property>
    <name>hive.compactor.worker.threads</name>
    <value>1</value>
</property>
```



2.添加Hive元数据(使用mysql存储)



```
INSERT INTO NEXT_LOCK_ID VALUES(1);
INSERT INTO NEXT_COMPACTION_QUEUE_ID VALUES(1);
INSERT INTO NEXT_TXN_ID VALUES(1);
COMMIT;
```



否则会抱错误



**说明：初始时这三个表没有数据，如果不添加数据，会报以下错误： org.apache.hadoop.hive.ql.lockmgr.DbTxnManager FAILED: Error in acquiring locks: Error communicating with the metastore**

![Screenshot 2020-05-26 at 12.55.50](https://tva1.sinaimg.cn/large/007S8ZIlgy1gf5uhmgn8rj30sm01m0t0.jpg)

![Screenshot 2020-05-26 at 13.45.20](https://tva1.sinaimg.cn/large/007S8ZIlgy1gf5sxr9gg3j30jk00wjrh.jpg)



3.启动hadoop集群

```
start-all.sh
```



4.建立测试表



```
use test;
create table t1(id int, name string) 
clustered by (id) into 8 buckets 
stored as orc TBLPROPERTIES ('transactional'='true');
```





```
insert into t1 values (1,'aaa');
insert into t1 values (2,'bbb');
update t1 set name='ccc' where id=1;
delete from t1 where id=2; 
```







```xml
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
--><configuration>
  <!-- WARNING!!! This file is auto generated for documentation purposes ONLY! -->
  <!-- WARNING!!! Any changes you make to this file will be ignored by Hive.   -->
  <!-- WARNING!!! You must make your changes in hive-site.xml instead.         -->
  <!-- Hive Execution Parameters -->
  <property>
    <name>system:java.io.tmpdir</name>
    <value>/tmp/hive/java</value>
  </property>
  <property>
    <name>system:user.name</name>
    <value>${user.name}</value>
  </property>
  <property>
    <name>hive.support.concurrency</name>
    <value>true</value>
    <description>
      Whether Hive supports concurrency control or not. 
      A ZooKeeper instance must be up and running when using zookeeper Hive lock manager 
    </description>
  </property>
<property>
    <name>hive.enforce.bucketing</name>
    <value>true</value>
    <description>Whether bucketing is enforced. If true, while inserting into the table, bucketing is enforced.</description>
  </property>
<property>
<name>hive.exec.dynamic.partition</name>
    <value>true</value>
    <description>Whether or not to allow dynamic partitions in DML/DDL.</description>
  </property>
<property>
    <name>hive.txn.manager</name>
    <value>org.apache.hadoop.hive.ql.lockmgr.DbTxnManager</value>
    <description>
      Set to org.apache.hadoop.hive.ql.lockmgr.DbTxnManager as part of turning on Hive
      transactions, which also requires appropriate settings for hive.compactor.initiator.on,
      hive.compactor.worker.threads, hive.support.concurrency (true), hive.enforce.bucketing
      (true), and hive.exec.dynamic.partition.mode (nonstrict).
      The default DummyTxnManager replicates pre-Hive-0.13 behavior and provides
      no transactions.
    </description>
  </property>
<property>
    <name>hive.compactor.initiator.on</name>
    <value>true</value>
    <description>
      Whether to run the initiator and cleaner threads on this metastore instance or not.
      Set this to true on one instance of the Thrift metastore service as part of turning
      on Hive transactions. For a complete list of parameters required for turning on
      transactions, see hive.txn.manager.
    </description>
  </property>
  <property>
    <name>hive.compactor.worker.threads</name>
    <value>1</value>
    <description>
      How many compactor worker threads to run on this metastore instance. Set this to a
      positive number on one or more instances of the Thrift metastore service as part of
      turning on Hive transactions. For a complete list of parameters required for turning
      on transactions, see hive.txn.manager.
      Worker threads spawn MapReduce jobs to do compactions. They do not do the compactions
      themselves. Increasing the number of worker threads will decrease the time it takes
      tables or partitions to be compacted once they are determined to need compaction.
      It will also increase the background load on the Hadoop cluster as more MapReduce jobs
      will be running in the background.
    </description>
  </property>
</configuration>

```





![image-20200526144125523](https://tva1.sinaimg.cn/large/007S8ZIlgy1gf5uis2petj30nu04w3z8.jpg)

![Screenshot 2020-05-26 at 10.55.09](https://tva1.sinaimg.cn/large/007S8ZIlgy1gf5uk8fhonj30oe0500te.jpg)







##### Hive 元数据







![Screenshot 2020-05-26 at 14.56.03](https://tva1.sinaimg.cn/large/007S8ZIlgy1gf5uze9kl6j318o0p446s.jpg)



![Screenshot 2020-05-26 at 14.50.01](https://tva1.sinaimg.cn/large/007S8ZIlgy1gf5vkrugvcj318k05w0x2.jpg)



![Screenshot 2020-05-26 at 15.04.52](https://tva1.sinaimg.cn/large/007S8ZIlgy1gf5vl2vbfpj30h407cq4k.jpg)



![Screenshot 2020-05-26 at 15.05.01](https://tva1.sinaimg.cn/large/007S8ZIlgy1gf5vlaxz2gj30jg0du75v.jpg)





建立测试表:



```
use test;
create table t1(id int, name string) 
clustered by (id) into 8 buckets 
stored as orc TBLPROPERTIES ('transactional'='true');
```



测试操作



```
insert into t1 values (1,'aaa');
insert into t1 values (2,'bbb');
update t1 set name='ccc' where id=1;
delete from t1 where id=2; 
```









##### References:



Hive基础教程： https://juejin.im/post/5dde18cdf265da05fc66d92e



Hive函数split中分号";"作为分隔符报错的问题解决：https://blog.csdn.net/dj_2009291007/article/details/78667695





HortonWorks Ambari: 部署及管理指南:

[https://medium.com/erens-tech-book/%E5%AE%89%E8%A3%9D-hortonworks-ambari-2-5-a54d5f22dc5a](https://medium.com/erens-tech-book/安裝-hortonworks-ambari-2-5-a54d5f22dc5a)



https://cloud.tencent.com/developer/article/1433190



https://github.com/apache/hive/blob/master/metastore/scripts/upgrade/mysql/hive-txn-schema-2.1.0.mysql.sql





附录：



```txt
create table cars(Car string,MPG double,Cylinders int,Displacement double,Horsepower double, Weight double,Acceleration double,Model int,Origin string) row format delimited fields terminated by ',';


FAILED: ParseException line 1:196 mismatched input '<EOF>' expecting StringLiteral near 'by' in table row format's field separator


 create table mycar2(Car string,MPG double,Cylinders int,Displacement double,Horsepower double, Weight double,Acceleration double,Model int,Origin string)row format delimited fields terminated by '\073';




 load data local inpath '/home/student/Desktop/cars.csv' overwrite into table mycar2;



insert into leo_car values('Chevrolet Chevelle Malibu',18,8,307,130,3504,12,70,'US'),('Buick Skylark 320',15,8,350,165,3693,11.5,70,'US'),('Plymouth Satellite',18,8,318,150,3436,11,70,'US'),('AMC Rebel SST',16,8,304,150,3433,12,70,'US'),('Ford Torino',17,8,302,140,3449,10.5,70,'UK');

FAILED: SemanticException [Error 10294]: Attempt to do update or delete using transaction manager that does not support these operations.



Set hive.support.concurrency = true;
Set hive.enforce.bucketing = true;
set hive.exec.dynamic.partition.mode = nonstrict;
set hive.txn.manager = org.apache.hadoop.hive.ql.lockmgr.DbTxnManager;
set hive.compactor.initiator.on = true;
set hive.compactor.worker.threads =1;


create table t1(id int, name string) 
clustered by (id) into 8 buckets 
stored as orc TBLPROPERTIES ('transactional'='true');



CREATE TABLE TXNS (
  TXN_ID bigint PRIMARY KEY,
  TXN_STATE char(1) NOT NULL,
  TXN_STARTED bigint NOT NULL,
  TXN_LAST_HEARTBEAT bigint NOT NULL,
  TXN_USER varchar(128) NOT NULL,
  TXN_HOST varchar(128) NOT NULL,
  TXN_AGENT_INFO varchar(128),
  TXN_META_INFO varchar(128),
  TXN_HEARTBEAT_COUNT int
) ENGINE=InnoDB DEFAULT CHARSET=latin1;

CREATE TABLE TXN_COMPONENTS (
  TC_TXNID bigint NOT NULL,
  TC_DATABASE varchar(128) NOT NULL,
  TC_TABLE varchar(128) NOT NULL,
  TC_PARTITION varchar(767),
  TC_OPERATION_TYPE char(1) NOT NULL,
  FOREIGN KEY (TC_TXNID) REFERENCES TXNS (TXN_ID)
) ENGINE=InnoDB DEFAULT CHARSET=latin1;

CREATE TABLE COMPLETED_TXN_COMPONENTS (
  CTC_TXNID bigint NOT NULL,
  CTC_DATABASE varchar(128) NOT NULL,
  CTC_TABLE varchar(128),
  CTC_PARTITION varchar(767)
) ENGINE=InnoDB DEFAULT CHARSET=latin1;

CREATE TABLE NEXT_TXN_ID (
  NTXN_NEXT bigint NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=latin1;
INSERT INTO NEXT_TXN_ID VALUES(1);

CREATE TABLE HIVE_LOCKS (
  HL_LOCK_EXT_ID bigint NOT NULL,
  HL_LOCK_INT_ID bigint NOT NULL,
  HL_TXNID bigint,
  HL_DB varchar(128) NOT NULL,
  HL_TABLE varchar(128),
  HL_PARTITION varchar(767),
  HL_LOCK_STATE char(1) not null,
  HL_LOCK_TYPE char(1) not null,
  HL_LAST_HEARTBEAT bigint NOT NULL,
  HL_ACQUIRED_AT bigint,
  HL_USER varchar(128) NOT NULL,
  HL_HOST varchar(128) NOT NULL,
  HL_HEARTBEAT_COUNT int,
  HL_AGENT_INFO varchar(128),
  HL_BLOCKEDBY_EXT_ID bigint,
  HL_BLOCKEDBY_INT_ID bigint,
  PRIMARY KEY(HL_LOCK_EXT_ID, HL_LOCK_INT_ID),
  KEY HIVE_LOCK_TXNID_INDEX (HL_TXNID)
) ENGINE=InnoDB DEFAULT CHARSET=latin1;

CREATE INDEX HL_TXNID_IDX ON HIVE_LOCKS (HL_TXNID);

CREATE TABLE NEXT_LOCK_ID (
  NL_NEXT bigint NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=latin1;
INSERT INTO NEXT_LOCK_ID VALUES(1);

CREATE TABLE COMPACTION_QUEUE (
  CQ_ID bigint PRIMARY KEY,
  CQ_DATABASE varchar(128) NOT NULL,
  CQ_TABLE varchar(128) NOT NULL,
  CQ_PARTITION varchar(767),
  CQ_STATE char(1) NOT NULL,
  CQ_TYPE char(1) NOT NULL,
  CQ_TBLPROPERTIES varchar(2048),
  CQ_WORKER_ID varchar(128),
  CQ_START bigint,
  CQ_RUN_AS varchar(128),
  CQ_HIGHEST_TXN_ID bigint,
  CQ_META_INFO varbinary(2048),
  CQ_HADOOP_JOB_ID varchar(32)
) ENGINE=InnoDB DEFAULT CHARSET=latin1;

CREATE TABLE COMPLETED_COMPACTIONS (
  CC_ID bigint PRIMARY KEY,
  CC_DATABASE varchar(128) NOT NULL,
  CC_TABLE varchar(128) NOT NULL,
  CC_PARTITION varchar(767),
  CC_STATE char(1) NOT NULL,
  CC_TYPE char(1) NOT NULL,
  CC_TBLPROPERTIES varchar(2048),
  CC_WORKER_ID varchar(128),
  CC_START bigint,
  CC_END bigint,
  CC_RUN_AS varchar(128),
  CC_HIGHEST_TXN_ID bigint,
  CC_META_INFO varbinary(2048),
  CC_HADOOP_JOB_ID varchar(32)
) ENGINE=InnoDB DEFAULT CHARSET=latin1;

CREATE TABLE NEXT_COMPACTION_QUEUE_ID (
  NCQ_NEXT bigint NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=latin1;
INSERT INTO NEXT_COMPACTION_QUEUE_ID VALUES(1);

CREATE TABLE AUX_TABLE (
  MT_KEY1 varchar(128) NOT NULL,
  MT_KEY2 bigint NOT NULL,
  MT_COMMENT varchar(255),
  PRIMARY KEY(MT_KEY1, MT_KEY2)
) ENGINE=InnoDB DEFAULT CHARSET=latin1;

CREATE TABLE WRITE_SET (
  WS_DATABASE varchar(128) NOT NULL,
  WS_TABLE varchar(128) NOT NULL,
  WS_PARTITION varchar(767),
  WS_TXNID bigint NOT NULL,
  WS_COMMIT_ID bigint NOT NULL,
  WS_OPERATION_TYPE char(1) NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=latin1;

```





### Hive 的数据类型





### Hive的数据查询

​	

##### 简单查询



>  查看表结构



```java
desc emp;
```



> 查询所有数据

```
select * from emp;
```



> 支持计算



```
select salary*12 from emp;
```



>  取消mapreduce操作



```
set hive.fetch.task.conversion=more;
```







##### 过滤





##### 排序